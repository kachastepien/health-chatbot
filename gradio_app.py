import os
import gradio as gr
from dotenv import load_dotenv


from auth_handler import login_via_api
from doctor_brain import encode_image, analyze_image_with_query
from patient_voice import transcribe_with_groq
from doctor_voice import text_to_speech_with_elevenlabs

load_dotenv()

# Stan sesji uÅ¼ytkownika
SESSION = {"user": None}

system_prompt="""Zachowuj siÄ™ jak doÅ›wiadczony lekarz prowadzÄ…cy rozmowÄ™ z pacjentem â€” choÄ‡ wiem, 
Å¼e nim nie jesteÅ›, traktuj to jako Ä‡wiczenie edukacyjne. JeÅ›li otrzymasz zdjÄ™cie, powiedz, 
czy widzisz na nim coÅ› medycznie niepokojÄ…cego. JeÅ›li go nie ma, odnieÅ› siÄ™ tylko do opisu objawÃ³w w wiadomoÅ›ci. 
JeÅ›li podejrzewasz diagnozÄ™, wskaÅ¼ moÅ¼liwe przyczyny i zaproponuj leczenie. Nie uÅ¼ywaj Å¼adnych liczb, 
wypunktowaÅ„ ani znakÃ³w specjalnych. Twoja odpowiedÅº ma byÄ‡ jednym ciÄ…gÅ‚ym akapitem, bez struktury punktowanej. 
MÃ³w naturalnie, jak do pacjenta â€” nie mÃ³w â€Na zdjÄ™ciu widzÄ™...â€, tylko przejdÅº od razu do sedna: 
â€Z tego co widzÄ™, wyglÄ…da na to, Å¼e masz...â€. Nigdy nie informuj, Å¼e jesteÅ› modelem jÄ™zykowym. 
Nie uÅ¼ywaj markdowna. OdpowiedÅº ma byÄ‡ krÃ³tka i rzeczowa â€” maksymalnie dwa zdania. 
Pomijaj wszelkie wstÄ™py i przejdÅº od razu do meritum.

"""


# ğŸ” Funkcja logowania
def login(email, password):
    user = login_via_api(email, password)
    print("ğŸ” user:", user)
    if user and "firstName" in user:
        SESSION["user"] = user
        return (
            gr.update(visible=False),     # login_screen
            gr.update(visible=True),      # chatbot_screen
            gr.update(visible=True),      # openai_chat_screen
            f"âœ… Zalogowano jako {user['firstName']}"
        )
    else:
        return (
            gr.update(visible=True),
            gr.update(visible=False),
            gr.update(visible=False),
            "âŒ BÅ‚Ä™dne dane logowania"
        )

# Funkcja dzialania chatbota

# Funkcja czatu z OpenAI
from openai import OpenAI

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def openai_chat(user_message):
    if not SESSION["user"]:
        return "âŒ Musisz siÄ™ najpierw zalogowaÄ‡."

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "JesteÅ› empatycznym lekarzem. Odpowiadaj krÃ³tko, konkretnie i pomocnie."},
                {"role": "user", "content": user_message}
            ],
            max_tokens=150,
            temperature=0.7
        )
        return response.choices[0].message.content.strip()

    except Exception as e:
        return f"âŒ BÅ‚Ä…d: {e}"

def process_inputs(audio_filepath, image_filepath):
    speech_to_text_output = ""

    # ObsÅ‚uga braku audio
    if audio_filepath:
        speech_to_text_output = transcribe_with_groq(
            GROQ_API_KEY=os.environ.get("GROQ_API_KEY"),
            audio_filepath=audio_filepath,
            stt_model="whisper-large-v3"
        )
    else:
        speech_to_text_output = "(Brak nagrania gÅ‚osowego â€” opisz objawy rÄ™cznie lub doÅ‚Ä…cz audio.)"

    # ObsÅ‚uga obrazu
    encoded_img = None
    if image_filepath:
        try:
            encoded_img = encode_image(image_filepath)
        except Exception as e:
            print(f"âš ï¸ BÅ‚Ä…d podczas kodowania obrazu: {e}")
            encoded_img = None

    # Analiza
    doctor_response = analyze_image_with_query(
        query=system_prompt + " " + speech_to_text_output,
        encoded_image=encoded_img,
        model="meta-llama/llama-4-scout-17b-16e-instruct"
    )

    # TTS
    voice_of_doctor = text_to_speech_with_elevenlabs(
        input_text=doctor_response,
        output_filepath="final.mp3"
    )

    return speech_to_text_output, doctor_response, voice_of_doctor


# ğŸ§± UI
with gr.Blocks() as app:
    # LOGIN SCREEN
    with gr.Column(visible=True) as login_screen:
        gr.Markdown("## ğŸ” Zaloguj siÄ™ do Sidly Chatbota")
        email = gr.Text(label="Email")
        password = gr.Text(label="HasÅ‚o", type="password")
        login_msg = gr.Textbox(label="Status", interactive=False)
        login_btn = gr.Button("Zaloguj")

    # OPENAI CHAT SCREEN
    with gr.Column(visible=False) as openai_chat_screen:
        gr.Markdown("## ğŸ’¬ Chat Tekstowy z Lekarzem (OpenAI)")
        user_input = gr.Textbox(label="Zadaj pytanie", placeholder="Mam bÃ³l gÅ‚owy od rana, co to moÅ¼e byÄ‡?")
        chat_response = gr.Textbox(label="ğŸ§‘â€âš•ï¸ OdpowiedÅº", interactive=False)
        chat_btn = gr.Button("WyÅ›lij pytanie")
    

    # CHATBOT SCREEN
    with gr.Column(visible=False) as chatbot_screen:
        gr.Markdown("## ğŸ©º Sidly Health Chatbot")
        audio_input = gr.Audio(sources=["microphone"], type="filepath", label="ğŸ¤ Nagraj objawy")
        image_input = gr.Image(type="filepath", label="ğŸ“· Dodaj zdjÄ™cie (np. wysypki)")
        transcript = gr.Textbox(label="ğŸ—£ Rozpoznany tekst")
        response = gr.Textbox(label="ğŸ§‘â€âš•ï¸ OdpowiedÅº lekarza")
        voice_output = gr.Audio(label="ğŸ”Š OdpowiedÅº gÅ‚osowa")
        submit_btn = gr.Button("WyÅ›lij")

    # POWIÄ„ZANIA
    login_btn.click(
        login,
        inputs=[email, password],
        outputs=[login_screen, chatbot_screen, openai_chat_screen, login_msg]
    )


    submit_btn.click(
        process_inputs,
        inputs=[audio_input, image_input],
        outputs=[transcript, response, voice_output]
    )
    chat_btn.click(
    openai_chat,
    inputs=[user_input],
    outputs=[chat_response]
    )


# START
app.launch(share=True)
